{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot using cosine_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yk647MYg01Z"
      },
      "outputs": [],
      "source": [
        "!pip install newspaper3k\n",
        "from newspaper import Article\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import text\n",
        "from pickle import UNICODE\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraping, downloading and parsing text data\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "article=Article('https://www.gov.uk/student-visa')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "\n",
        "corpus = article.text\n",
        "\n",
        "print(corpus)"
      ],
      "metadata": {
        "id": "yosoh4NlhAi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Pre-Processing\n",
        "\n",
        "def clean_text(corpus):\n",
        "  newline_re = r'[\\n]+'\n",
        "  white_space_re = r\"\\s+\"\n",
        "\n",
        "  corpus = re.sub(newline_re, r' ', corpus, flags=re.UNICODE)\n",
        "  corpus = re.sub(white_space_re, r' ', corpus, flags=re.UNICODE)\n",
        "\n",
        "  return corpus\n",
        "\n",
        "def all_steps(text, steps):\n",
        "  steps_dict = {'clean': clean_text}\n",
        "\n",
        "  if len(steps):\n",
        "    for step in steps:\n",
        "      text = steps_dict[step](text)\n",
        "  return text\n",
        "\n",
        "text = corpus\n",
        "steps = ['clean']\n",
        "data = all_steps(text, steps)\n",
        "\n",
        "text = data\n",
        "\n",
        "sentence_list = nltk.sent_tokenize(text)\n",
        "print(sentence_list)"
      ],
      "metadata": {
        "id": "J6sRyWaAhCOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = re.sub(newline_re, r' ', corpus, flags=re.UNICODE)\n",
        "newline_re = r'[\\n]+'\n",
        "\n",
        "white_space_re = r\"\\s+\"\n",
        "\n",
        "  \n",
        "  corpus = re.sub(white_space_re, r' ', corpus, flags=re.UNICODE)"
      ],
      "metadata": {
        "id": "dsYxJxkCSexP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index store the highest similarity score sentence\n",
        "\n",
        "def index_sort(list_var):\n",
        "  length = len(list_var)\n",
        "  list_index = list(range(0, length))\n",
        "\n",
        "  x = list_var\n",
        "\n",
        "  for i in range(length):\n",
        "    for j in range(length):\n",
        "      if x[list_index[i]] > x[list_index[j]]:\n",
        "        temp = list_index[i]\n",
        "        list_index[i] = list_index[j]\n",
        "        list_index[j] = temp\n",
        "\n",
        "  return list_index"
      ],
      "metadata": {
        "id": "euRkByQNhcBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funtion to find the fit count matrix and cosine similarity\n",
        "\n",
        "def bot_response(user_input):\n",
        "  user_input = user_input.lower()\n",
        "  sentence_list.append(user_input)\n",
        "  bot_response = ''\n",
        "  cm = CountVectorizer().fit_transform(sentence_list)\n",
        "  similarity_scores = cosine_similarity(cm[-1], cm)\n",
        "  similarity_scores_list = similarity_scores.flatten()\n",
        "  index = index_sort(similarity_scores_list)\n",
        "  index = index[1:]\n",
        "  response_flag = 0\n",
        "\n",
        "  j = 0\n",
        "  for i in range(len(index)):\n",
        "    if similarity_scores_list[index[i]] > 0.25:\n",
        "      bot_response = bot_response+' '+sentence_list[index[i]]\n",
        "      response_flag = 1\n",
        "      j = j+1\n",
        "    \n",
        "    if j > 2:\n",
        "      break\n",
        "    \n",
        "  \n",
        "\n",
        "  if response_flag == 0:\n",
        "    bot_response = bot_response+' '+\"I DONT UNDERSTAND YOU , PLEASE ASK SOMETHING RELATED TO VISA\" \n",
        "\n",
        "  sentence_list.remove(user_input)\n",
        "\n",
        "  return bot_response"
      ],
      "metadata": {
        "id": "kKRDi5Gjhdaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chatbot Question and Answering \n",
        "\n",
        "print('Im sunny, here to answer your queries')\n",
        "\n",
        "exit_list = ['exit']\n",
        "\n",
        "while(True):\n",
        "  user_input = input()\n",
        "  if user_input.lower() in exit_list:\n",
        "    break\n",
        "  \n",
        "  else:\n",
        "    if user_input == None:\n",
        "      print(\"\\n\")\n",
        "      print('SUNNY:\\n'+bot_response(user_input))\n",
        "      print(\"\\n\")\n",
        "  \n",
        "    else:\n",
        "      print(\"\\n\")\n",
        "      print('SUNNY:'+bot_response(user_input))\n",
        "      print(\"\\n\")\n",
        "      "
      ],
      "metadata": {
        "id": "MqFIOopghjCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}